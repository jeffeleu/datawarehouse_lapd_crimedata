# Data Warehouse of LAPD Crime Data

## Data Explanation
The data comes from an inital reporting of a crime to law enforcement (either from emergency phone calls (911), visits to the police station, or online reporting, etc) in the city of Los Angeles. Law enforcement officers or operators collect information about the reported crime such as the type of crime, location, time and date of occurrence, descriptions of suspects or victims. The information is then classified and documented (according to the data source, the original crime reports were typed on paper). The provided dataset is a transcribed version of the original paper documentation.

## Sourcing 

To source the data, I explored catalog.data.gov and selected a dataset that caught my interest: the 'Crime Data from 2020 to Present' provided by the LAPD. To better understand the dataset, I reviewed its origin and located the accompanying data dictionary. I then created an Excel file to store the data dictionary for easy reference.

To process and analyze the data, I wrote a Python script utilizing Pandas and NumPy. The script loads the dataset, creates a DataFrame, and outputs the column names and the shape of the data, providing an overview of its structure.

## Storing

The data was stored using Microsoft Azure Storage. A resource group and a container were created within Azure to house the data. To upload the sourced data, the sourcing script was updated to utilize the BlobServiceClient, BlobClient, and ContainerClient classes from the azure.storage.blob library. These classes enable efficient connection establishment, access to the appropriate container and blob, and streamlined data upload.

## Modeling

The data modeling process began with identifying the facts and dimensions. The fact table includes foreign keys referencing the dimension tables. The following dimensions were identified for the data warehouse: Crime, Premise, Victim, Datetime, Location, and Status. Next, DBSchema was used to visualize and design the database system. The SQL script generated by the model was then saved for data warehousing purposes.

## Extract, Transform, Load

To start, I installed the following:

    azure-storage-blob  #for data in storage

    pyarrow #working with data and dataframes

    psycopg2 sqlalchemy #interact with postgresql
  
and used these libraries for manipulating data, transforming, and loading: 

    import pandas as pd 

    import numpy as np

    import json

    from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient

    from io import StringIO

    from datetime import datetime 

    from math import ceil

    import datetime

    import calendar

    from sqlalchemy import create_engine


After creating a DataFrame by utilizing JSON and retrieving the container client from Azure, the data transformation began. The transformation process included correcting the 'Premis Cd' column to 'Int64' to eliminate decimal values. Additionally, the "DATE OCC" and "TIME OCC" columns were combined into a single "DATETIME OCC" column for simplicity. Several columns, including 'DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'Rpt Dist No', 'Part 1-2', 'Mocodes', 'Weapon Used Cd', 'Weapon Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', and 'Cross Street', were dropped as they were not necessary for the data warehouse.

The data mapping for the dimensions and fact table was then carried out, with each table being mapped, ordered, and converted into a DataFrame.

Once the fact and dimension dataframes were complete, an Azure Database for PostgreSQL was created. The database URL was used to generate a SQLAlchemy engine, which facilitated data transfer to the data warehouse via DataGrip. Prior to loading the data, the SQL scripts from the data model were used to structure the data warehouse in DataGrip. After the data was successfully loaded, Power BI was used for further analysis and visualization.

## Data Visualization on Power BI

[PowerBI Link](https://cuny907-my.sharepoint.com/:u:/g/personal/jeffery_liu02_login_cuny_edu/EUNAHHHGcXVAgov9Ob07UtcBeBkH69n87BlrPtuZTGkWPw?e=mbavx3)

Bar Chart Comparing Average Victim Age by Area

![bar_chartof_avg_vict_by_area](https://github.com/jeffeleu/DataWarehouse_LAPD_Crime__Data/assets/160162018/d3c0133b-6d4f-4464-87dd-a14fe24368ae)

Line Chart Showing the Number of Crimes by Year

![linechartofnumberofcrimesbyyear](https://github.com/jeffeleu/DataWarehouse_LAPD_Crime__Data/assets/160162018/568517aa-35fc-45f4-b5bb-3dba4596b0be)

Map Locating Crimes with Latitude and Longitude

![latlon](https://github.com/jeffeleu/DataWarehouse_LAPD_Crime__Data/assets/160162018/4b698ed9-49f1-4a1f-8a19-003a0bdad79e)

Pie Chart Showing Crimes by Description from 2020 to Present

![piechartofcrimesbydescr](https://github.com/jeffeleu/DataWarehouse_LAPD_Crime__Data/assets/160162018/c2dbef8e-8253-4ab4-8032-99b41994f20b)

## Sources
[LAPD Crime Data](https://catalog.data.gov/dataset/crime-data-from-2020-to-present)

[Data Dictionary](https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data)
